# Security Compass - Technical Assessment

## Requirements
- Python 3.13.0
- Docker installed 
- Helm installed w/ repos configured

## To Run
`python vulnreport.py -c <chartname> -v <chartversion>`

e.g. `python vulnreport.py -c bitnami/nginx -v 18.2.5` (assuming the bitnami repo is added to helm)

See `python vulnreport.py -h` for instructions

## Notes on Implemenation

### Some notes on why I chose this approach:
- I chose to use Python as I suspected it would be the easiest way to implement the command output parsing and csv file output portions. I have sample programs in my github repos I could have drawn from to save me time here, had I gotten that far. Another advantage was that I could process everything in memory withtout having to deal with any temporary file creation and cleanup, which I almost certainly would have had to do in bash. 

- I did some pre-investigation looking at the two scanner options. Trivy seemed straight forward, had slightly clearer documentation, and provided a docker option for portability. I opted for it primarily for those reasons. My thinking being: in a production environment trivy could be always available on the kubernetes cluster (or in an artifact repo) with a mostly frictionless install/run path, vs. potentially having to manage different distribution types for grype depending on the target environment. 

- My hope was that I could do this all as part of a single tool, rather than having to manage two: a python script and a wrapper shell script. Python simplifies of lot of user input error handling, whereas this can be a bit tricky in bash script. Python would - in theory - allow the tool to be more user-friendly and less error-prone. 

### What I Would Have Done Differently

See the various `#TODO` and `#BUG` comments in the code. 

1. Firstly, given more time I would have finished the tool. I had a plan in mind to do so (see TODO comments) but ran out of time troubleshooting some issues. I suspect I would have completed most of it given another hour or so. 
    1. I lost a fair bit of time trying to wrangle the subprocess code generated by ChatGPT to get it to work the way I expected. 

1. Rather than use chained subprocess calls, I probably would have used pyyaml to get the initial list of images, since `helm template ...` outputs as yaml by default. 

1. Rather than set up different functions for various subprocess commands, I would have spent time developing a single command runner wrapper function with appropriate params to allow it to be piped to further commands, or not, depending on need. Likely by setting a stdin=None default param that I can override by passing a process.stdout as an override.

1. Test for edge cases and add more robust error-checking at each stage of the process. 
    1. I know of at least one case where trivy reported files that were too large to be scanned that would have needed to be handled. 

1. As resource cleanup was a requirement, I might have checked `docker images` for any resulting images that had been pulled and remove those 

1. Although for the purposes of this assessment I was pushing directly to my master branch in github, under ordinary circumstances I would have created a development branch to push to. 